{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "\n",
    "import datasets\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "from sae.data import chunk_and_tokenize\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1542644afdd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_dataset(\n",
    "    \"togethercomputer/RedPajama-Data-1T-Sample\", split=\"train[:1000]\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "dataset = chunk_and_tokenize(dataset, tokenizer, max_seq_len=32)\n",
    "model = AutoModel.from_pretrained(\"gpt2\", device_map={\"\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regression(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.d_in = d_in\n",
    "        self.d_out = d_out\n",
    "        self.linear = nn.Linear(d_in, d_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class NuclearNormLoss(nn.Module):\n",
    "    def __init__(self, lam=0.01, rank=None):\n",
    "        super().__init__()\n",
    "        self.lam = lam\n",
    "        self.rank = rank or 1\n",
    "\n",
    "    def forward(self, pred, target, weight):\n",
    "        mse_loss = torch.mean((pred - target) ** 2)\n",
    "        _, S, _ = torch.linalg.svd(weight)\n",
    "        # penalize all other ranks\n",
    "        nuclear_norm = torch.sum(S[self.rank :])\n",
    "        return mse_loss + self.lam * nuclear_norm, mse_loss, nuclear_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FVU: 3.9277420043945312\n",
      "FVU: 3.9332618713378906\n",
      "FVU: 3.9656481742858887\n",
      "FVU: 3.9733245372772217\n",
      "FVU: 3.9706435203552246\n",
      "FVU: 4.08003568649292\n",
      "FVU: 3.8771989345550537\n",
      "FVU: 4.0151262283325195\n",
      "FVU: 4.004677772521973\n",
      "FVU: 4.017975807189941\n",
      "FVU: 3.8584885597229004\n",
      "FVU: 4.045174598693848\n",
      "FVU: 3.9922409057617188\n",
      "FVU: 4.01267671585083\n",
      "FVU: 4.126893043518066\n",
      "FVU: 4.110725402832031\n",
      "FVU: 4.150299072265625\n",
      "FVU: 3.9668264389038086\n",
      "FVU: 3.9783287048339844\n",
      "FVU: 3.8852291107177734\n",
      "FVU: 3.9805259704589844\n",
      "FVU: 4.005075454711914\n",
      "FVU: 3.909733295440674\n",
      "FVU: 3.857121467590332\n",
      "FVU: 3.813244581222534\n",
      "FVU: 3.9511611461639404\n",
      "FVU: 3.895009994506836\n",
      "FVU: 3.986253499984741\n",
      "FVU: 4.015557289123535\n",
      "FVU: 3.9707953929901123\n",
      "FVU: 3.913961410522461\n",
      "FVU: 3.94234037399292\n",
      "FVU: 3.9815196990966797\n",
      "FVU: 3.9262137413024902\n",
      "FVU: 3.8375720977783203\n",
      "FVU: 3.9302451610565186\n",
      "FVU: 3.9152674674987793\n",
      "FVU: 4.061468124389648\n",
      "FVU: 4.047924995422363\n",
      "FVU: 4.0532426834106445\n",
      "FVU: 4.088166236877441\n",
      "FVU: 3.941070079803467\n",
      "FVU: 4.030582904815674\n",
      "FVU: 3.8918137550354004\n",
      "FVU: 3.9753470420837402\n",
      "FVU: 3.83601450920105\n",
      "FVU: 3.912623882293701\n",
      "FVU: 3.896749496459961\n",
      "FVU: 4.012635707855225\n",
      "FVU: 3.9596948623657227\n",
      "FVU: 3.774843215942383\n",
      "FVU: 3.868516445159912\n",
      "FVU: 3.946012020111084\n",
      "FVU: 3.983858823776245\n",
      "FVU: 4.045093059539795\n",
      "FVU: 4.012013912200928\n",
      "FVU: 4.049172878265381\n",
      "FVU: 3.9433655738830566\n",
      "FVU: 3.8461625576019287\n",
      "FVU: 4.070673942565918\n",
      "FVU: 3.9191577434539795\n",
      "FVU: 3.9134604930877686\n",
      "FVU: 3.9380483627319336\n",
      "FVU: 3.863163709640503\n",
      "FVU: 4.076275825500488\n",
      "FVU: 4.020873069763184\n",
      "FVU: 3.897425413131714\n",
      "FVU: 3.9232594966888428\n",
      "FVU: 3.937798261642456\n",
      "FVU: 3.9343972206115723\n",
      "FVU: 3.898263454437256\n",
      "FVU: 4.011436462402344\n",
      "FVU: 4.0028839111328125\n",
      "FVU: 4.049868583679199\n",
      "FVU: 3.9497182369232178\n",
      "FVU: 3.9962449073791504\n",
      "FVU: 4.064845561981201\n",
      "FVU: 4.068573951721191\n",
      "FVU: 3.965308666229248\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 122\u001b[0m\n\u001b[1;32m    120\u001b[0m ranks \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m384\u001b[39m, \u001b[38;5;241m768\u001b[39m]\n\u001b[1;32m    121\u001b[0m layer_pairs \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m), (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m8\u001b[39m)]  \u001b[38;5;66;03m# Add more layer pairs as needed\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m \u001b[43mcreate_scree_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_pairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mranks\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 105\u001b[0m, in \u001b[0;36mcreate_scree_plot\u001b[0;34m(model, dataset, layer_pairs, ranks)\u001b[0m\n\u001b[1;32m    103\u001b[0m r2_values \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rank \u001b[38;5;129;01min\u001b[39;00m ranks:\n\u001b[0;32m--> 105\u001b[0m     r2 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     r2_values\u001b[38;5;241m.\u001b[39mappend(r2)\n\u001b[1;32m    108\u001b[0m color \u001b[38;5;241m=\u001b[39m colors[idx \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mlen\u001b[39m(colors)]\n",
      "Cell \u001b[0;32mIn[5], line 51\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(model, dataset, i, j, rank, batch_size, lam, lr, steps, eval_steps, device)\u001b[0m\n\u001b[1;32m     42\u001b[0m layer_i_acts, layer_j_acts \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     43\u001b[0m     model_out\u001b[38;5;241m.\u001b[39mhidden_states[i],\n\u001b[1;32m     44\u001b[0m     model_out\u001b[38;5;241m.\u001b[39mhidden_states[j],\n\u001b[1;32m     45\u001b[0m )\n\u001b[1;32m     47\u001b[0m pred, target \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     48\u001b[0m     linear_model(F\u001b[38;5;241m.\u001b[39mnormalize(layer_i_acts, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)),\n\u001b[1;32m     49\u001b[0m     F\u001b[38;5;241m.\u001b[39mnormalize(layer_j_acts, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     50\u001b[0m )\n\u001b[0;32m---> 51\u001b[0m loss, l2, nnorm \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinear_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m l2_unreduced \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean((pred \u001b[38;5;241m-\u001b[39m target) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     54\u001b[0m var \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mvar(target, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/sae/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/sae/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 21\u001b[0m, in \u001b[0;36mNuclearNormLoss.forward\u001b[0;34m(self, pred, target, weight)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, pred, target, weight):\n\u001b[1;32m     20\u001b[0m     mse_loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean((pred \u001b[38;5;241m-\u001b[39m target) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m     _, S, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msvd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# penalize all other ranks\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     nuclear_norm \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(S[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrank :])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_and_evaluate(\n",
    "    model,\n",
    "    dataset,\n",
    "    i,\n",
    "    j,\n",
    "    rank,\n",
    "    batch_size=64,\n",
    "    lam=0.1,\n",
    "    lr=1e-2,\n",
    "    steps=20,\n",
    "    eval_steps=10,\n",
    "    device=\"cuda\",\n",
    "):\n",
    "    split_dataset = dataset.train_test_split(test_size=0.2)\n",
    "    train_dataloader = DataLoader(\n",
    "        split_dataset[\"train\"], batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "    test_dataloader = DataLoader(\n",
    "        split_dataset[\"test\"], batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "\n",
    "    linear_model = Regression(d_in=model.config.n_embd, d_out=model.config.n_embd).to(\n",
    "        device\n",
    "    )\n",
    "\n",
    "    nn.init.zeros_(linear_model.linear.weight)\n",
    "    nn.init.zeros_(linear_model.linear.bias)\n",
    "\n",
    "    criterion = NuclearNormLoss(lam=lam, rank=rank)\n",
    "    opt = torch.optim.SGD(linear_model.parameters(), lr=lr)\n",
    "\n",
    "    train_iter = cycle(train_dataloader)\n",
    "\n",
    "    for step in range(steps):\n",
    "        train_batch = next(train_iter)\n",
    "        opt.zero_grad()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model_out = model(\n",
    "                train_batch[\"input_ids\"].to(device), output_hidden_states=True\n",
    "            )\n",
    "        layer_i_acts, layer_j_acts = (\n",
    "            model_out.hidden_states[i],\n",
    "            model_out.hidden_states[j],\n",
    "        )\n",
    "\n",
    "        pred, target = (\n",
    "            linear_model(F.normalize(layer_i_acts, p=2, dim=-1)),\n",
    "            F.normalize(layer_j_acts, p=2, dim=-1),\n",
    "        )\n",
    "        loss, l2, nnorm = criterion(pred, target, linear_model.linear.weight)\n",
    "\n",
    "        l2_unreduced = torch.mean((pred - target) ** 2, dim=0)\n",
    "        var = torch.var(target, dim=0)\n",
    "\n",
    "        # print(l2_unreduced.mean(-1), var.mean(-1))\n",
    "\n",
    "        fvu = (l2_unreduced / var).mean()\n",
    "        \n",
    "        print(f\"FVU: {fvu}\")\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    # Evaluate on test set\n",
    "    linear_model.eval()\n",
    "    total_fvu = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, test_batch in enumerate(test_dataloader):\n",
    "            model_out = model(\n",
    "                test_batch[\"input_ids\"].to(device), output_hidden_states=True\n",
    "            )\n",
    "            layer_i_acts, layer_j_acts = (\n",
    "                model_out.hidden_states[i],\n",
    "                model_out.hidden_states[j],\n",
    "            )\n",
    "            pred, target = (\n",
    "                linear_model(F.normalize(layer_i_acts, p=2, dim=-1)),\n",
    "                F.normalize(layer_j_acts, p=2, dim=-1),\n",
    "            )\n",
    "            l2_unreduced = torch.mean((pred - target) ** 2, dim=0)\n",
    "            var = torch.var(target, dim=0)\n",
    "            fvu = (l2_unreduced / var).mean()\n",
    "\n",
    "            total_fvu += fvu.item()\n",
    "\n",
    "            if i >= eval_steps:\n",
    "                break\n",
    "\n",
    "    test_fvu = total_fvu / eval_steps\n",
    "    test_r2 = 1 - test_fvu\n",
    "\n",
    "    return test_r2\n",
    "\n",
    "\n",
    "def create_scree_plot(model, dataset, layer_pairs, ranks):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    colors = [\"b\", \"g\", \"r\", \"c\", \"m\", \"y\", \"k\"]  # Add more colors if needed\n",
    "\n",
    "    for idx, (i, j) in enumerate(layer_pairs):\n",
    "        r2_values = []\n",
    "        for rank in ranks:\n",
    "            r2 = train_and_evaluate(model, dataset, i, j, rank, steps=10)\n",
    "            r2_values.append(r2)\n",
    "\n",
    "        color = colors[idx % len(colors)]\n",
    "        plt.plot(ranks, r2_values, f\"{color}o-\", label=f\"Layers {i} to {j}\")\n",
    "\n",
    "    plt.xlabel(\"Rank\")\n",
    "    plt.ylabel(\"R^2\")\n",
    "    plt.title(\"Scree Plot for Multiple Layer Pairs\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Usage\n",
    "ranks = [1, 2, 4, 8, 16, 32, 384, 768]\n",
    "layer_pairs = [(1, 1), (1, 4), (1, 8)]  # Add more layer pairs as needed\n",
    "create_scree_plot(model, dataset, layer_pairs, ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
