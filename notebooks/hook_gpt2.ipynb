{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing consequences of interventions on gpt2, and how they match up against our SAE's\n",
    "from functools import partial\n",
    "\n",
    "import datasets\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from einops import einsum\n",
    "from safetensors.torch import load_file\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from sae.data import chunk_and_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2\"\n",
    "ckpt_path = \"/home/sid/tensor-sae/checkpoints/all-layer-test/sae.safetensors\"\n",
    "# ckpt_path = \"/home/sid/tensor-sae/checkpoints/pythia14m-all-layers-rp1t/pythia14m-all-layers-rp1t-sample_20240901_123737/layers.0_layers.1_layers.2_layers.3_layers.4_layers.5/sae-2298.safetensors\"\n",
    "# model_name = \"EleutherAI/pythia-14m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of output embeddings: torch.Size([2, 768])\n",
      "shape of causal embeddings: torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name).cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "sae_ckpt = load_file(ckpt_path, device=\"cuda\")\n",
    "\n",
    "feature_encoder_weights = sae_ckpt.get(\"encoder.weight\", sae_ckpt.get(\"weight\"))\n",
    "feature_encoder_bias = sae_ckpt.get(\"encoder.bias\", sae_ckpt.get(\"bias\"))\n",
    "# legacy keys\n",
    "feature_decoder_weights = sae_ckpt[\"decoder.weight\"]\n",
    "feature_decoder_bias = sae_ckpt[\"decoder.bias\"]\n",
    "\n",
    "intervention_index = 2\n",
    "readout_index = 4\n",
    "\n",
    "\n",
    "def create_hooks(\n",
    "    model,\n",
    "    intervention_index,\n",
    "    readout_index,\n",
    "    lambda_value,\n",
    "    feature_encoder_weights,\n",
    "    feature_encoder_bias,\n",
    "    feature_decoder_weights,\n",
    "):\n",
    "    first_activation_positions = None\n",
    "    consequent_embeddings = None\n",
    "    causal_embeddings = None\n",
    "    # j < k in layer idx\n",
    "    v_j = None\n",
    "    v_k = None\n",
    "\n",
    "    def strengthen_sae_feature(module, input, output, layer_offset=0):\n",
    "        nonlocal first_activation_positions, causal_embeddings, v_j, v_k\n",
    "\n",
    "        embed_dim = output[0].shape[-1]\n",
    "        feature_encoder_segment = feature_encoder_weights[\n",
    "            :,\n",
    "            (intervention_index - layer_offset) * embed_dim : (\n",
    "                intervention_index - layer_offset + 1\n",
    "            )\n",
    "            * embed_dim,\n",
    "        ]\n",
    "        feature_decoder_segment = feature_decoder_weights[\n",
    "            :,\n",
    "            (intervention_index - layer_offset) * embed_dim : (\n",
    "                intervention_index - layer_offset + 1\n",
    "            )\n",
    "            * embed_dim,\n",
    "        ]\n",
    "\n",
    "        feature_activation = (\n",
    "            einsum(output[0], feature_encoder_segment.T, \"b s e, e n -> b s n\")\n",
    "            - feature_encoder_bias\n",
    "        )\n",
    "        feature_activation, max_feature_index = torch.max(feature_activation, dim=-1)\n",
    "\n",
    "        first_activation_positions = (feature_activation > 0).float().argmax(dim=1)\n",
    "        has_activation = (feature_activation > 0).any(dim=1)\n",
    "        first_activation_positions[~has_activation] = -1\n",
    "\n",
    "        batch_size, seq_len, embed_dim = output[0].shape\n",
    "\n",
    "        mask = torch.arange(seq_len, device=output[0].device).unsqueeze(0).expand(\n",
    "            batch_size, -1\n",
    "        ) == first_activation_positions.unsqueeze(1)\n",
    "\n",
    "        causal_embeddings = output[0]\n",
    "        mask = mask.unsqueeze(-1).expand(-1, -1, embed_dim)\n",
    "\n",
    "        v_j = (\n",
    "            feature_decoder_segment.unsqueeze(0)\n",
    "            .expand(output[0].shape[0], -1, -1)\n",
    "            .gather(1, max_feature_index.unsqueeze(-1).expand(-1, -1, embed_dim))\n",
    "        )\n",
    "        new_output = output[0] + lambda_value * mask * v_j\n",
    "\n",
    "        intervention_decoder_segment = feature_decoder_weights[\n",
    "            :,\n",
    "            (readout_index - layer_offset) * embed_dim : (\n",
    "                readout_index - layer_offset + 1\n",
    "            )\n",
    "            * embed_dim,\n",
    "        ]\n",
    "        v_k = (\n",
    "            intervention_decoder_segment.unsqueeze(0)\n",
    "            .expand(output[0].shape[0], -1, -1)\n",
    "            .gather(1, max_feature_index.unsqueeze(-1).expand(-1, -1, embed_dim))\n",
    "        )\n",
    "\n",
    "        new_outputs = [new_output] + list(output[1:])\n",
    "        return tuple(new_outputs)\n",
    "\n",
    "    def return_consequent_layer(module, input, output):\n",
    "        nonlocal consequent_embeddings, first_activation_positions\n",
    "\n",
    "        batch_size, seq_len, embed_dim = output[0].shape\n",
    "\n",
    "        mask = torch.arange(seq_len, device=output[0].device).unsqueeze(0).expand(\n",
    "            batch_size, -1\n",
    "        ) == first_activation_positions.unsqueeze(1)\n",
    "        mask = mask.unsqueeze(-1).expand(-1, -1, embed_dim)\n",
    "\n",
    "        filtered_output = output[0]\n",
    "        consequent_embeddings = filtered_output.sum(dim=1)\n",
    "\n",
    "        # Return the original output unchanged\n",
    "        return output\n",
    "\n",
    "    if \"gpt\" in model_name:\n",
    "        intervention_hook = model.transformer.h[\n",
    "            intervention_index\n",
    "        ].register_forward_hook(\n",
    "            partial(strengthen_sae_feature, layer_offset=intervention_index)\n",
    "        )\n",
    "        readout_hook = model.transformer.h[readout_index].register_forward_hook(\n",
    "            return_consequent_layer\n",
    "        )\n",
    "    else:\n",
    "        intervention_hook = model.gpt_neox.layers[\n",
    "            intervention_index\n",
    "        ].register_forward_hook(\n",
    "            partial(strengthen_sae_feature, layer_offset=intervention_index)\n",
    "        )\n",
    "        readout_hook = model.gpt_neox.layers[readout_index].register_forward_hook(\n",
    "            return_consequent_layer\n",
    "        )\n",
    "\n",
    "    return (\n",
    "        intervention_hook,\n",
    "        readout_hook,\n",
    "        lambda: first_activation_positions,\n",
    "        lambda: consequent_embeddings,\n",
    "        lambda: causal_embeddings,\n",
    "        lambda: v_j,\n",
    "        lambda: v_k,\n",
    "    )\n",
    "\n",
    "\n",
    "def process_text(\n",
    "    model,\n",
    "    inputs,\n",
    "    intervention_index,\n",
    "    readout_index,\n",
    "    lam,\n",
    "    feature_encoder_weights,\n",
    "    feature_encoder_bias,\n",
    "    feature_decoder_weights,\n",
    "):\n",
    "    (\n",
    "        intervention_hook,\n",
    "        readout_hook,\n",
    "        get_first_activation_positions,\n",
    "        get_consequent_embeddings,\n",
    "        get_causal_embeddings,\n",
    "        get_v_j,\n",
    "        get_v_k,\n",
    "    ) = create_hooks(\n",
    "        model,\n",
    "        intervention_index,\n",
    "        readout_index,\n",
    "        lam,\n",
    "        feature_encoder_weights,\n",
    "        feature_encoder_bias,\n",
    "        feature_decoder_weights,\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model(**inputs)\n",
    "\n",
    "    first_activation_positions = get_first_activation_positions()\n",
    "    consequent_embeddings = get_consequent_embeddings()\n",
    "    causal_embeddings = get_causal_embeddings()\n",
    "    v_j = get_v_j()\n",
    "    v_k = get_v_k()\n",
    "\n",
    "    intervention_hook.remove()\n",
    "    readout_hook.remove()\n",
    "\n",
    "    return (\n",
    "        first_activation_positions,\n",
    "        consequent_embeddings,\n",
    "        causal_embeddings,\n",
    "        v_j,\n",
    "        v_k,\n",
    "    )\n",
    "\n",
    "\n",
    "# Example usage\n",
    "intervention_index = 4\n",
    "readout_index = 5\n",
    "text = [\"Hello, world!\", \"Hello, world!\"]\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "# Assuming you have these variables defined\n",
    "# feature_encoder_weights, feature_encoder_bias, feature_decoder_weights\n",
    "\n",
    "first_activation_positions, consequent_embeddings, causal_embeddings, _, _ = (\n",
    "    process_text(\n",
    "        model,\n",
    "        inputs,\n",
    "        intervention_index,\n",
    "        readout_index,\n",
    "        1.0,\n",
    "        feature_encoder_weights,\n",
    "        feature_encoder_bias,\n",
    "        feature_decoder_weights,\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"shape of output embeddings: {consequent_embeddings.shape}\")\n",
    "print(f\"shape of causal embeddings: {causal_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next code we would need to add:\n",
    "#filter out any batch elements where the SAE doesn't trigger\n",
    "#compare to activations from a hook on the clean sequence\n",
    "#subtract, compute comparisons, etc.!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I suspect the most efficient way to go about thos jacobian computation is to modify the gpt2 forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_jacobian(model, j_activations, i, j, k):\n",
    "    \"\"\"\n",
    "    Compute the Jacobian of layer k's activations with respect to layer j's activations at position i.\n",
    "\n",
    "    Args:\n",
    "    - model: GPT2Model instance\n",
    "    - j_activations: activations of layer j (shape: [batch_size, seq_len, hidden_size])\n",
    "    - i: token position\n",
    "    - j: index of the input layer\n",
    "    - k: index of the output layer\n",
    "\n",
    "    Returns:\n",
    "    - Jacobian matrix\n",
    "    \"\"\"\n",
    "    # Ensure j_activations requires grad\n",
    "    j_activations.requires_grad_(True)\n",
    "\n",
    "    # Forward pass to get k_activations\n",
    "    def forward_to_k(x):\n",
    "        # Forward pass from j to k\n",
    "        activations = x\n",
    "        for layer_idx in range(j, k + 1):\n",
    "            if \"gpt\" in model_name:\n",
    "                activations = model.transformer.h[layer_idx](activations)[0]\n",
    "            else:\n",
    "                activations = model.gpt_neox.layers[layer_idx](activations)[0]\n",
    "        return activations[:, i, :]\n",
    "\n",
    "    # Compute Jacobian\n",
    "    jacobian = torch.autograd.functional.jacobian(forward_to_k, j_activations)\n",
    "\n",
    "    return jacobian.squeeze(0, 2)[:, i, :]  # selecting only token pos i.\n",
    "    # But if we're pre-computing, we could just return the jacobian.squeeze(0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_proc must be <= 16. Reducing num_proc to 16 for dataset of size 16.\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.load_dataset(\n",
    "    \"togethercomputer/RedPajama-Data-1T-Sample\",\n",
    "    split=\"train\",\n",
    "    trust_remote_code=True,\n",
    ").select(range(16))\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenized = chunk_and_tokenize(dataset, tokenizer, max_seq_len=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'overflow_to_sample_mapping'],\n",
       "    num_rows: 4299\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect activations from GPT2\n",
    "sample = tokenized[0][\"input_ids\"].unsqueeze(0)\n",
    "\n",
    "j, k = 1, 2\n",
    "lam = 1e-2\n",
    "(\n",
    "    first_activation_positions,\n",
    "    consequent_embeddings_intervened,\n",
    "    causal_embeddings,\n",
    "    v_j,\n",
    "    v_k,\n",
    ") = process_text(\n",
    "    model,\n",
    "    {\n",
    "        \"input_ids\": sample.cuda(),\n",
    "        \"attention_mask\": torch.ones_like(sample, device=\"cuda:1\"),\n",
    "    },\n",
    "    j,\n",
    "    k,\n",
    "    lam,\n",
    "    feature_encoder_weights,\n",
    "    feature_encoder_bias,\n",
    "    feature_decoder_weights,\n",
    ")\n",
    "(_, consequent_embeddings_clean, _, _, _) = process_text(\n",
    "    model,\n",
    "    {\n",
    "        \"input_ids\": sample.cuda(),\n",
    "        \"attention_mask\": torch.ones_like(sample, device=\"cuda:1\"),\n",
    "    },\n",
    "    j,\n",
    "    k,\n",
    "    0,\n",
    "    feature_encoder_weights,\n",
    "    feature_encoder_bias,\n",
    "    feature_decoder_weights,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacobian shape: torch.Size([768, 768])\n"
     ]
    }
   ],
   "source": [
    "# Generate random input\n",
    "# batch_size, seq_len = 1, 10\n",
    "# j_activations = torch.randn(batch_size, seq_len, 768, device=\"cuda:1\")\n",
    "i = 0\n",
    "jacobian = compute_jacobian(model, causal_embeddings, i, j, k)\n",
    "\n",
    "print(f\"Jacobian shape: {jacobian.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error_a: 4.025733346679772e-08\n"
     ]
    }
   ],
   "source": [
    "# Check consequent_embeddings ~= original_embeddings_at_the_higher_layer + jacobian @ v_j * lam\n",
    "with torch.no_grad():\n",
    "    jacobian_approx_a = (\n",
    "        consequent_embeddings_clean + (v_j[:, i, :] @ jacobian.T) * lam\n",
    "    )\n",
    "\n",
    "error_a = torch.mean((consequent_embeddings_intervened - jacobian_approx_a) ** 2)\n",
    "\n",
    "print(f\"error_a: {error_a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 768])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_j.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_active_latents_first_pos(\n",
    "    output, feature_encoder_weights, feature_encoder_bias, i, j\n",
    "):\n",
    "    # concat hidden states for layer range\n",
    "    all_hidden_states = torch.cat(\n",
    "        [output.hidden_states[idx] for idx in range(i, j + 1)], dim=-1\n",
    "    )\n",
    "    feature_activation = (\n",
    "        einsum(all_hidden_states, feature_encoder_weights.T, \"b s e, e n -> b s n\")\n",
    "        - feature_encoder_bias\n",
    "    )\n",
    "    max_feature_activation, _ = torch.max(feature_activation, dim=-1)\n",
    "    # get first positions where maximal feature is activated\n",
    "    first_activation_positions = (\n",
    "        (max_feature_activation > 0).float().argmax(dim=1, keepdim=True)\n",
    "    )\n",
    "    expanded_pos = first_activation_positions.unsqueeze(-1).expand(\n",
    "        -1, -1, all_hidden_states.shape[-1]\n",
    "    )\n",
    "    token_activations = all_hidden_states.gather(1, expanded_pos)\n",
    "    num_fired = (token_activations > 0).sum(dim=-1)\n",
    "\n",
    "    return num_fired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_dataset(\n",
    "    \"togethercomputer/RedPajama-Data-1T-Sample\",\n",
    "    split=\"train\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenized = chunk_and_tokenize(dataset, tokenizer, max_seq_len=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define, lower and upper bounds for layers\n",
    "i, j = 0, 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [01:37<00:00,  1.53s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_samples = 8192\n",
    "bsz = 128\n",
    "# for each sample compute activation positions and fired pre-act latents\n",
    "sample = tokenized.select(range(num_samples))\n",
    "\n",
    "dist = []\n",
    "\n",
    "for batch in tqdm(sample.iter(bsz), total=num_samples // bsz):\n",
    "    with torch.no_grad():\n",
    "        out = model(\n",
    "            input_ids=batch[\"input_ids\"].cuda().unsqueeze(0), output_hidden_states=True\n",
    "        )\n",
    "    num_active = get_active_latents_first_pos(\n",
    "        out, feature_encoder_weights, feature_encoder_bias, i, j\n",
    "    )\n",
    "    dist.extend(num_active.squeeze().cpu().tolist())\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "# Create the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Active Latents on Tokens activating Max Feature\")\n",
    "_ = plt.hist(dist, bins=30, edgecolor=\"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_active_latents_heatmap(\n",
    "    output, feature_encoder_weights, feature_encoder_bias, i, j\n",
    "):\n",
    "    # Concatenate hidden states for layer range\n",
    "    all_hidden_states = torch.cat(\n",
    "        [output.hidden_states[idx] for idx in range(i, j + 1)], dim=-1\n",
    "    )\n",
    "\n",
    "    # Calculate feature activation\n",
    "    feature_activation = (\n",
    "        torch.einsum(\"bse,en->bsn\", all_hidden_states, feature_encoder_weights.T)\n",
    "        - feature_encoder_bias\n",
    "    )\n",
    "\n",
    "    # Count number of active latents for each token\n",
    "    num_active_latents = (feature_activation > 0).sum(dim=-1)\n",
    "\n",
    "    return num_active_latents\n",
    "\n",
    "\n",
    "def visualize_heatmap_batch(heatmap_data, token_labels_batch, max_tokens_display=30):\n",
    "    batch_size, seq_length = heatmap_data.shape\n",
    "\n",
    "    # Create a figure with subplots for each batch item\n",
    "    fig, axes = plt.subplots(batch_size, 1, figsize=(20, 3 * batch_size), squeeze=False)\n",
    "    fig.suptitle(\"Active Latents Heatmap (Batch)\", fontsize=16)\n",
    "\n",
    "    for b in range(batch_size):\n",
    "        ax = axes[b, 0]\n",
    "\n",
    "        # Limit the number of tokens displayed\n",
    "        display_tokens = min(seq_length, max_tokens_display)\n",
    "        heatmap = heatmap_data[b, :display_tokens].unsqueeze(0).cpu().numpy()\n",
    "        token_labels = token_labels_batch[b][:display_tokens]\n",
    "\n",
    "        sns.heatmap(\n",
    "            heatmap,\n",
    "            cmap=\"YlOrRd\",\n",
    "            xticklabels=token_labels,\n",
    "            yticklabels=[\"\"],\n",
    "            ax=ax,\n",
    "            cbar=(b == batch_size - 1),\n",
    "        )  # Only show colorbar for the last subplot\n",
    "\n",
    "        ax.set_title(f\"Batch item {b}\")\n",
    "        ax.set_xlabel(\"Tokens\")\n",
    "\n",
    "        # Rotate and align x-axis labels for better readability\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\")\n",
    "\n",
    "        # Add ellipsis if not all tokens are displayed\n",
    "        if display_tokens < seq_length:\n",
    "            ax.text(\n",
    "                display_tokens + 0.5,\n",
    "                0.5,\n",
    "                \"...\",\n",
    "                verticalalignment=\"center\",\n",
    "                horizontalalignment=\"left\",\n",
    "            )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_latents_heatmap(i, j):\n",
    "    sample_input = tokenized.select(range(4))\n",
    "    out = model(input_ids=sample_input[\"input_ids\"].cuda(), output_hidden_states=True)\n",
    "\n",
    "    active_latents_tokenwise = get_active_latents_heatmap(\n",
    "        out, feature_encoder_weights, feature_encoder_bias, i, j\n",
    "    )\n",
    "    visualize_heatmap_batch(\n",
    "        active_latents_tokenwise,\n",
    "        [tokenizer.convert_ids_to_tokens(x) for x in sample_input[\"input_ids\"]],\n",
    "        j,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_causal_attribution_strength(\n",
    "    j,\n",
    "    k,\n",
    "    model,\n",
    "    inputs,\n",
    "    feature_encoder_weights,\n",
    "    feature_encoder_bias,\n",
    "    feature_decoder_weights,\n",
    "    lambda_value: float = 1.0,\n",
    "):\n",
    "    (\n",
    "        first_activation_positions,\n",
    "        consequent_embeddings_intervened,\n",
    "        causal_embeddings,\n",
    "        v_j,\n",
    "        v_k,\n",
    "    ) = process_text(\n",
    "        model,\n",
    "        inputs,\n",
    "        intervention_index,\n",
    "        readout_index,\n",
    "        lambda_value,\n",
    "        feature_encoder_weights,\n",
    "        feature_encoder_bias,\n",
    "        feature_decoder_weights,\n",
    "    )\n",
    "    \n",
    "    print(\"First activation positions:\", first_activation_positions)\n",
    "\n",
    "    expanded_pos = (\n",
    "        first_activation_positions.unsqueeze(-1)\n",
    "        .unsqueeze(-1)\n",
    "        .expand(-1, -1, causal_embeddings.shape[-1])\n",
    "    )\n",
    "    v_j = v_j.gather(1, expanded_pos).squeeze(1)\n",
    "    v_k = v_k.gather(1, expanded_pos).squeeze(1)\n",
    "\n",
    "    jacobian = torch.stack(\n",
    "        [\n",
    "            compute_jacobian(\n",
    "                model, causal_embeddings[idx].unsqueeze(0), pos.item(), j, k\n",
    "            )\n",
    "            for idx, pos in enumerate(first_activation_positions)\n",
    "        ]\n",
    "    )\n",
    "    # proportion of causality explained: compute vk.T(Jv_j) / ||v_k||^2\n",
    "    v_k_norm_squared = torch.sum(v_k**2, dim=-1)  # shape: (B,)\n",
    "    # Compute the whole expression using einsum\n",
    "    proportion_explained = (\n",
    "        torch.einsum(\"bie,be,bi->b\", jacobian, v_j, v_k) / v_k_norm_squared\n",
    "    )\n",
    "    # print(torch.einsum(\"bie,be,bi->b\", jacobian, v_j, v_k).shape, v_k_norm_squared.shape)\n",
    "    # error term\n",
    "    pred = torch.einsum(\"bie,be->bi\", jacobian, v_j)\n",
    "    strength = F.cosine_similarity(pred, v_k, dim=-1)\n",
    "    error = torch.mean((pred - v_k) ** 2, dim=-1)\n",
    "\n",
    "    return proportion_explained, strength, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First activation positions: tensor([0, 0, 0, 0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# TODO: unbatch the jacobian\n",
    "i, j = 0, 1\n",
    "\n",
    "inputs = {\"input_ids\": sample.select(range(4))[\"input_ids\"].cuda()}\n",
    "\n",
    "explained_causality, strengths, error = compute_causal_attribution_strength(\n",
    "    i,\n",
    "    j,\n",
    "    model,\n",
    "    inputs,\n",
    "    feature_encoder_weights,\n",
    "    feature_encoder_bias,\n",
    "    feature_decoder_weights,\n",
    "    1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.3011, 1.4086, 1.3021, 1.3011], device='cuda:0'),\n",
       " tensor([0.8747, 0.8816, 0.8749, 0.8747], device='cuda:0'),\n",
       " tensor([0.0002, 0.0002, 0.0002, 0.0002], device='cuda:0'))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explained_causality, strengths, error"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
